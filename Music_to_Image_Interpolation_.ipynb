{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gio961gio/Music-to-Image-Interpolation/blob/main/Music_to_Image_Interpolation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obap7xijCDqx"
      },
      "source": [
        "# SETUP\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!git clone https://github.com/gio961gio/Music-to-Image-Interpolation.git\n",
        "sys.path.append(\"/content/Music-to-Image-Interpolation/Scripts\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_0uMDyov4n0",
        "outputId": "0de68092-1b45-4e1e-c812-2649435115d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Music-to-Image-Interpolation'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 50 (delta 9), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (50/50), 26.23 KiB | 5.25 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rfjhDwnd5HY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Install Tesseract\n",
        "%%capture\n",
        "!sudo apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install \"anything2image\" Package\n",
        "\n",
        "!pip install anything2image"
      ],
      "metadata": {
        "id": "OKbjpIol1XFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg4xVf_4u9vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67543e31-7ff6-449c-84a4-41cff9460734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing packages: 100%|██████████| 5/5 [02:38<00:00, 31.62s/it]\n"
          ]
        }
      ],
      "source": [
        "# @title Install Packages\n",
        "from tqdm import tqdm\n",
        "import subprocess\n",
        "\n",
        "packages_to_install = [\"diffusers\", \"pydub\", \"pytesseract\", \"torchvision==0.16.2\", \"torchaudio --upgrade\"]\n",
        "\n",
        "for package in tqdm(packages_to_install, desc=\"Installing packages\"):\n",
        "    if \"torchvision==0.16.2\" in package:\n",
        "        subprocess.run(\"pip install torchvision==0.16.2\", shell=True, capture_output=True)\n",
        "    elif \"torchaudio --upgrade\" in package:\n",
        "        subprocess.run(\"pip install torchaudio --upgrade\", shell=True, capture_output=True)\n",
        "    else:\n",
        "        subprocess.run([\"pip\", \"install\", package], capture_output=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E-64PVo99re"
      },
      "outputs": [],
      "source": [
        "# @title Install Image_Generator\n",
        "import anything2image.imagebind as ib\n",
        "import torch\n",
        "from diffusers import StableUnCLIPImg2ImgPipeline\n",
        "\n",
        "# construct models\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = StableUnCLIPImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-1-unclip\", torch_dtype=torch.float16\n",
        ").to(device)\n",
        "model = ib.imagebind_huge(pretrained=True).eval().to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaxaokhueImJ"
      },
      "outputs": [],
      "source": [
        "# @title Install Inpainter\n",
        "#### Calling detexting model parts ####\n",
        "\n",
        "from detext import TesseractTextDetector, LocalSDInpainter\n",
        "\n",
        "\n",
        "text_detector = TesseractTextDetector('/usr/bin/tesseract')\n",
        "inpainter = LocalSDInpainter()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4UraAwZhv46",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Create Folders\n",
        "import os\n",
        "\n",
        "# Definisci il percorso delle cartelle che desideri creare\n",
        "x = '/content/audio'\n",
        "y = '/content/audio_segments'\n",
        "\n",
        "# Utilizza la funzione os.makedirs() per creare le cartelle\n",
        "os.makedirs(x)\n",
        "os.makedirs(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQmMHMiye4bn"
      },
      "source": [
        "# **AUDIO CHOP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sVteOS1iuTW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Load Audio\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import shutil\n",
        "\n",
        "# Definisci il percorso della cartella di destinazione\n",
        "cartella_destinazione = '/content/audio'\n",
        "# Definisci il nome del file caricato\n",
        "nome_file_caricato = list(uploaded.keys())[0]\n",
        "\n",
        "# Sposta il file nella cartella di destinazione\n",
        "shutil.move(nome_file_caricato, cartella_destinazione)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9MdowXDezRD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Segments Number\n",
        "from audio_stuff import Audio_stuff\n",
        "\n",
        "num_segments = 8 # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "audio_processing = Audio_stuff(num_segments)\n",
        "input_audio_path = audio_processing.input_audio_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_dO4da0-Ayu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Audio to Image Embedding\n",
        "import os\n",
        "cartella = '/content/audio_segments'\n",
        "prompts = []\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def visualize_video_colab(video_path):\n",
        "    mp4 = open(video_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(\"\"\"\n",
        "    <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url)\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x in os.listdir(cartella):\n",
        "    audio_paths= [os.path.join(cartella, x)]\n",
        "    embeddings = model.forward({\n",
        "        ib.ModalityType.AUDIO: ib.load_and_transform_audio_data(audio_paths, device),\n",
        "    })\n",
        "    embeddings = embeddings[ib.ModalityType.AUDIO]\n",
        "    prompts.append(embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_UY8r0xAM5N"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41sowhp_lIKz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Generate\n",
        "from interpolation_module import walk\n",
        "from audio_stuff import stuff_for_test\n",
        "\n",
        "\n",
        "\n",
        "fps = 5 # @param {type:\"number\"}\n",
        "\n",
        "batch_size = 5 # @param {type:\"number\"}\n",
        "\n",
        "detext = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "num_interpolation_steps, audio_offsets = stuff_for_test(input_audio_path,(num_segments+1),fps)\n",
        "if num_interpolation_steps[0] % batch_size!=0:\n",
        "  raise ValueError( f\" 'batch_size' value must be a divider of {num_interpolation_steps[0]} \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    video_path = walk(prompts=prompts,\n",
        "                      seeds=[42]*len(prompts),\n",
        "                      num_interpolation_steps=num_interpolation_steps,\n",
        "                      audio_filepath=input_audio_path,\n",
        "                      audio_start_sec=audio_offsets[0],\n",
        "                      batch_size=batch_size,\n",
        "                      fps=fps,\n",
        "                      name='name',\n",
        "                      num_inference_steps=20 # @param {type:\"number\"}\n",
        "                      ,detext = detext,\n",
        "                      inpainter = inpainter,\n",
        "                      text_detector = text_detector,\n",
        "                      pipe = pipe\n",
        "                      )\n",
        "\n",
        "visualize_video_colab(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download Video\n",
        "from google.colab import files\n",
        "\n",
        "# Definisci il percorso del file da scaricare\n",
        "percorso_file = \"/content/dreams/name/name.mp4\"\n",
        "\n",
        "# Scarica il file\n",
        "files.download(percorso_file)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PDu7Ta_WTO4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}